{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "file_path = './tuning_results/tune_19/result/tuning_result_tfbind8_lr0.05.csv' \n",
    "df = pd.read_csv(file_path) \n",
    "df = df.sort_values(by='mean (100th)',ascending=False)\n",
    "df = df[df['mean (100th)']>0.95]\n",
    "print(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_fit_samples</th>\n",
       "      <th>sampling_lr</th>\n",
       "      <th>lengthscale</th>\n",
       "      <th>delta</th>\n",
       "      <th>eta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>classifier_free_guidance_weight</th>\n",
       "      <th>mean (100th)</th>\n",
       "      <th>std (100th)</th>\n",
       "      <th>mean (80th)</th>\n",
       "      <th>std (80th)</th>\n",
       "      <th>mean (50th)</th>\n",
       "      <th>std (50th)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.988339</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.820047</td>\n",
       "      <td>0.010891</td>\n",
       "      <td>0.650288</td>\n",
       "      <td>0.020193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.988339</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.820424</td>\n",
       "      <td>0.011271</td>\n",
       "      <td>0.645745</td>\n",
       "      <td>0.022213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.988339</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.820319</td>\n",
       "      <td>0.012415</td>\n",
       "      <td>0.642994</td>\n",
       "      <td>0.025989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.988339</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.820006</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.645878</td>\n",
       "      <td>0.025174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>16000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.987608</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.840609</td>\n",
       "      <td>0.016091</td>\n",
       "      <td>0.677095</td>\n",
       "      <td>0.020079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.987477</td>\n",
       "      <td>0.007660</td>\n",
       "      <td>0.818428</td>\n",
       "      <td>0.018572</td>\n",
       "      <td>0.647526</td>\n",
       "      <td>0.020534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.007340</td>\n",
       "      <td>0.820393</td>\n",
       "      <td>0.013013</td>\n",
       "      <td>0.639457</td>\n",
       "      <td>0.024121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.986980</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.838188</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.674140</td>\n",
       "      <td>0.015100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.986980</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.839479</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.675677</td>\n",
       "      <td>0.018222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.986951</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.842246</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.663057</td>\n",
       "      <td>0.018548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>16000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.986766</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>0.838054</td>\n",
       "      <td>0.017678</td>\n",
       "      <td>0.676250</td>\n",
       "      <td>0.022887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>16000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.986766</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>0.842215</td>\n",
       "      <td>0.012988</td>\n",
       "      <td>0.678477</td>\n",
       "      <td>0.015056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.986370</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>0.846958</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>0.665152</td>\n",
       "      <td>0.020010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>12000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.986290</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.828602</td>\n",
       "      <td>0.019187</td>\n",
       "      <td>0.668087</td>\n",
       "      <td>0.011865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>12000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.986290</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.829430</td>\n",
       "      <td>0.020512</td>\n",
       "      <td>0.667398</td>\n",
       "      <td>0.012750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.986259</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.840214</td>\n",
       "      <td>0.013580</td>\n",
       "      <td>0.667523</td>\n",
       "      <td>0.020487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.986134</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>0.844767</td>\n",
       "      <td>0.018087</td>\n",
       "      <td>0.668158</td>\n",
       "      <td>0.016175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>16000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>0.986087</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.836565</td>\n",
       "      <td>0.017502</td>\n",
       "      <td>0.679742</td>\n",
       "      <td>0.023850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>12000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.986051</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.833201</td>\n",
       "      <td>0.017571</td>\n",
       "      <td>0.668322</td>\n",
       "      <td>0.012729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>12000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.986051</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.832427</td>\n",
       "      <td>0.018017</td>\n",
       "      <td>0.670005</td>\n",
       "      <td>0.012441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.986046</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>0.842117</td>\n",
       "      <td>0.018934</td>\n",
       "      <td>0.681923</td>\n",
       "      <td>0.010045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.985941</td>\n",
       "      <td>0.006420</td>\n",
       "      <td>0.845438</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.667100</td>\n",
       "      <td>0.016164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.985890</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.842615</td>\n",
       "      <td>0.014131</td>\n",
       "      <td>0.670941</td>\n",
       "      <td>0.022335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.985890</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.839260</td>\n",
       "      <td>0.014803</td>\n",
       "      <td>0.674995</td>\n",
       "      <td>0.026171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.985890</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.839390</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.669254</td>\n",
       "      <td>0.022549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.985890</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.837887</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>0.666116</td>\n",
       "      <td>0.022953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.985890</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.838955</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.672805</td>\n",
       "      <td>0.026164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.985824</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>0.841218</td>\n",
       "      <td>0.011859</td>\n",
       "      <td>0.663887</td>\n",
       "      <td>0.019497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>16000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.985775</td>\n",
       "      <td>0.006997</td>\n",
       "      <td>0.840158</td>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.670673</td>\n",
       "      <td>0.019348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>16000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.985775</td>\n",
       "      <td>0.006997</td>\n",
       "      <td>0.836551</td>\n",
       "      <td>0.014111</td>\n",
       "      <td>0.672074</td>\n",
       "      <td>0.020393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.985762</td>\n",
       "      <td>0.008885</td>\n",
       "      <td>0.843642</td>\n",
       "      <td>0.013492</td>\n",
       "      <td>0.676796</td>\n",
       "      <td>0.018792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.985673</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.843774</td>\n",
       "      <td>0.015670</td>\n",
       "      <td>0.668031</td>\n",
       "      <td>0.017552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.985673</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.845071</td>\n",
       "      <td>0.013261</td>\n",
       "      <td>0.670652</td>\n",
       "      <td>0.020843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.985673</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.846908</td>\n",
       "      <td>0.015194</td>\n",
       "      <td>0.671090</td>\n",
       "      <td>0.017623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.985499</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.840165</td>\n",
       "      <td>0.013311</td>\n",
       "      <td>0.667854</td>\n",
       "      <td>0.016858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.985499</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.840847</td>\n",
       "      <td>0.014717</td>\n",
       "      <td>0.659248</td>\n",
       "      <td>0.014744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>0.985467</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.016623</td>\n",
       "      <td>0.632815</td>\n",
       "      <td>0.024758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>0.985467</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.811405</td>\n",
       "      <td>0.017757</td>\n",
       "      <td>0.626964</td>\n",
       "      <td>0.024360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.985448</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.816588</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.642893</td>\n",
       "      <td>0.021402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.985448</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.817905</td>\n",
       "      <td>0.018244</td>\n",
       "      <td>0.642712</td>\n",
       "      <td>0.019697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.985386</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>0.835425</td>\n",
       "      <td>0.011015</td>\n",
       "      <td>0.661541</td>\n",
       "      <td>0.017538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.985386</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>0.835038</td>\n",
       "      <td>0.011026</td>\n",
       "      <td>0.671396</td>\n",
       "      <td>0.013011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.985238</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.842467</td>\n",
       "      <td>0.017657</td>\n",
       "      <td>0.671300</td>\n",
       "      <td>0.012788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.985238</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.840793</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.671606</td>\n",
       "      <td>0.014488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.985073</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>0.840971</td>\n",
       "      <td>0.013086</td>\n",
       "      <td>0.657392</td>\n",
       "      <td>0.015304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_fit_samples  sampling_lr  lengthscale  delta   eta  alpha  \\\n",
       "199            17000         0.05         6.25   0.25  0.75   0.80   \n",
       "195            17000         0.05         6.25   0.25  0.75   0.85   \n",
       "187            17000         0.05         6.25   0.25  0.75   0.95   \n",
       "191            17000         0.05         6.25   0.25  0.75   0.90   \n",
       "86             16000         0.05         6.25   0.25  0.20   0.95   \n",
       "198            17000         0.05         6.25   0.25  0.75   0.80   \n",
       "183            17000         0.05         6.25   0.25  0.75   1.00   \n",
       "135            15000         0.05         6.25   0.25  0.30   0.85   \n",
       "139            15000         0.05         6.25   0.25  0.30   0.80   \n",
       "110            15000         0.05         6.25   0.25  0.25   0.90   \n",
       "82             16000         0.05         6.25   0.25  0.20   1.00   \n",
       "62             16000         0.05         6.25   0.25  0.15   1.00   \n",
       "70             15000         0.05         6.25   0.25  0.15   0.90   \n",
       "130            12000         0.05         6.25   0.25  0.30   0.90   \n",
       "102            12000         0.05         6.25   0.25  0.25   1.00   \n",
       "118            15000         0.05         6.25   0.25  0.25   0.80   \n",
       "30             14000         0.05         6.25   0.25  0.05   0.90   \n",
       "77             16000         0.05         6.25   0.25  0.15   0.80   \n",
       "138            12000         0.05         6.25   0.25  0.30   0.80   \n",
       "134            12000         0.05         6.25   0.25  0.30   0.85   \n",
       "42             16000         0.05         6.25   0.25  0.10   1.00   \n",
       "26             14000         0.05         6.25   0.25  0.05   0.95   \n",
       "119            15000         0.05         6.25   0.25  0.25   0.80   \n",
       "99             15000         0.05         6.25   0.25  0.20   0.80   \n",
       "115            15000         0.05         6.25   0.25  0.25   0.85   \n",
       "111            15000         0.05         6.25   0.25  0.25   0.90   \n",
       "95             15000         0.05         6.25   0.25  0.20   0.85   \n",
       "114            15000         0.05         6.25   0.25  0.25   0.85   \n",
       "107            16000         0.05         6.25   0.25  0.25   0.95   \n",
       "103            16000         0.05         6.25   0.25  0.25   1.00   \n",
       "19             12000         0.05         6.25   0.25  0.00   0.80   \n",
       "98             15000         0.05         6.25   0.25  0.20   0.80   \n",
       "78             15000         0.05         6.25   0.25  0.15   0.80   \n",
       "74             15000         0.05         6.25   0.25  0.15   0.85   \n",
       "86             15000         0.05         6.25   0.25  0.20   0.95   \n",
       "82             15000         0.05         6.25   0.25  0.20   1.00   \n",
       "173            13000         0.05         6.25   0.25  0.50   0.85   \n",
       "169            13000         0.05         6.25   0.25  0.50   0.90   \n",
       "190            17000         0.05         6.25   0.25  0.75   0.90   \n",
       "194            17000         0.05         6.25   0.25  0.75   0.85   \n",
       "127            15000         0.05         6.25   0.25  0.30   0.95   \n",
       "131            15000         0.05         6.25   0.25  0.30   0.90   \n",
       "94             15000         0.05         6.25   0.25  0.20   0.85   \n",
       "90             15000         0.05         6.25   0.25  0.20   0.90   \n",
       "102            15000         0.05         6.25   0.25  0.25   1.00   \n",
       "\n",
       "     classifier_free_guidance_weight  mean (100th)  std (100th)  mean (80th)  \\\n",
       "199                             -1.5      0.988339     0.007687     0.820047   \n",
       "195                             -1.5      0.988339     0.007687     0.820424   \n",
       "187                             -1.5      0.988339     0.007687     0.820319   \n",
       "191                             -1.5      0.988339     0.007687     0.820006   \n",
       "86                              -2.0      0.987608     0.007825     0.840609   \n",
       "198                             -2.0      0.987477     0.007660     0.818428   \n",
       "183                             -1.5      0.987302     0.007340     0.820393   \n",
       "135                             -1.5      0.986980     0.004225     0.838188   \n",
       "139                             -1.5      0.986980     0.004225     0.839479   \n",
       "110                             -2.0      0.986951     0.005840     0.842246   \n",
       "82                              -2.0      0.986766     0.007053     0.838054   \n",
       "62                              -2.0      0.986766     0.007053     0.842215   \n",
       "70                              -2.0      0.986370     0.005431     0.846958   \n",
       "130                             -2.0      0.986290     0.009140     0.828602   \n",
       "102                             -2.0      0.986290     0.009140     0.829430   \n",
       "118                             -2.0      0.986259     0.004256     0.840214   \n",
       "30                              -2.0      0.986134     0.003875     0.844767   \n",
       "77                              -2.5      0.986087     0.007113     0.836565   \n",
       "138                             -2.0      0.986051     0.007006     0.833201   \n",
       "134                             -2.0      0.986051     0.007006     0.832427   \n",
       "42                              -2.0      0.986046     0.007050     0.842117   \n",
       "26                              -2.0      0.985941     0.006420     0.845438   \n",
       "119                             -1.5      0.985890     0.006732     0.842615   \n",
       "99                              -1.5      0.985890     0.006732     0.839260   \n",
       "115                             -1.5      0.985890     0.006732     0.839390   \n",
       "111                             -1.5      0.985890     0.006732     0.837887   \n",
       "95                              -1.5      0.985890     0.006732     0.838955   \n",
       "114                             -2.0      0.985824     0.004416     0.841218   \n",
       "107                             -1.5      0.985775     0.006997     0.840158   \n",
       "103                             -1.5      0.985775     0.006997     0.836551   \n",
       "19                              -1.5      0.985762     0.008885     0.843642   \n",
       "98                              -2.0      0.985673     0.006404     0.843774   \n",
       "78                              -2.0      0.985673     0.006404     0.845071   \n",
       "74                              -2.0      0.985673     0.006404     0.846908   \n",
       "86                              -2.0      0.985499     0.005665     0.840165   \n",
       "82                              -2.0      0.985499     0.005665     0.840847   \n",
       "173                             -2.5      0.985467     0.008239     0.813725   \n",
       "169                             -2.5      0.985467     0.008239     0.811405   \n",
       "190                             -2.0      0.985448     0.008575     0.816588   \n",
       "194                             -2.0      0.985448     0.008575     0.817905   \n",
       "127                             -1.5      0.985386     0.006178     0.835425   \n",
       "131                             -1.5      0.985386     0.006178     0.835038   \n",
       "94                              -2.0      0.985238     0.006472     0.842467   \n",
       "90                              -2.0      0.985238     0.006472     0.840793   \n",
       "102                             -2.0      0.985073     0.006607     0.840971   \n",
       "\n",
       "     std (80th)  mean (50th)  std (50th)  \n",
       "199    0.010891     0.650288    0.020193  \n",
       "195    0.011271     0.645745    0.022213  \n",
       "187    0.012415     0.642994    0.025989  \n",
       "191    0.011750     0.645878    0.025174  \n",
       "86     0.016091     0.677095    0.020079  \n",
       "198    0.018572     0.647526    0.020534  \n",
       "183    0.013013     0.639457    0.024121  \n",
       "135    0.011091     0.674140    0.015100  \n",
       "139    0.010970     0.675677    0.018222  \n",
       "110    0.010827     0.663057    0.018548  \n",
       "82     0.017678     0.676250    0.022887  \n",
       "62     0.012988     0.678477    0.015056  \n",
       "70     0.015271     0.665152    0.020010  \n",
       "130    0.019187     0.668087    0.011865  \n",
       "102    0.020512     0.667398    0.012750  \n",
       "118    0.013580     0.667523    0.020487  \n",
       "30     0.018087     0.668158    0.016175  \n",
       "77     0.017502     0.679742    0.023850  \n",
       "138    0.017571     0.668322    0.012729  \n",
       "134    0.018017     0.670005    0.012441  \n",
       "42     0.018934     0.681923    0.010045  \n",
       "26     0.019917     0.667100    0.016164  \n",
       "119    0.014131     0.670941    0.022335  \n",
       "99     0.014803     0.674995    0.026171  \n",
       "115    0.012183     0.669254    0.022549  \n",
       "111    0.011212     0.666116    0.022953  \n",
       "95     0.014793     0.672805    0.026164  \n",
       "114    0.011859     0.663887    0.019497  \n",
       "107    0.009176     0.670673    0.019348  \n",
       "103    0.014111     0.672074    0.020393  \n",
       "19     0.013492     0.676796    0.018792  \n",
       "98     0.015670     0.668031    0.017552  \n",
       "78     0.013261     0.670652    0.020843  \n",
       "74     0.015194     0.671090    0.017623  \n",
       "86     0.013311     0.667854    0.016858  \n",
       "82     0.014717     0.659248    0.014744  \n",
       "173    0.016623     0.632815    0.024758  \n",
       "169    0.017757     0.626964    0.024360  \n",
       "190    0.019361     0.642893    0.021402  \n",
       "194    0.018244     0.642712    0.019697  \n",
       "127    0.011015     0.661541    0.017538  \n",
       "131    0.011026     0.671396    0.013011  \n",
       "94     0.017657     0.671300    0.012788  \n",
       "90     0.016304     0.671606    0.014488  \n",
       "102    0.013086     0.657392    0.015304  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "num_fit_samples_list = [10000,12000,13000,14000,15000,16000,17000,18000] \n",
    "best_tf8_hyper = None \n",
    "lengthscale = 6.25\n",
    "for num_fit_samples in num_fit_samples_list: \n",
    "    best_tf8_hyper1 =  pd.read_csv(f'tuning_results/tune_23/result/tuning_result_tfbind8_num_fit_samples{num_fit_samples}_lengthscale{lengthscale}_sampling_lr0.05_delta0.25.csv')\n",
    "    best_tf8_hyper1 = best_tf8_hyper1[best_tf8_hyper1['mean (100th)']>0.985]\n",
    "    best_tf8_hyper = pd.concat([best_tf8_hyper,best_tf8_hyper1])\n",
    "best_tf8_hyper_1 = best_tf8_hyper[['eta', 'alpha', 'classifier_free_guidance_weight']].to_numpy()\n",
    "best_tf8_hyper_1 = np.unique(best_tf8_hyper_1,axis=0)\n",
    "print(len(best_tf8_hyper_1))\n",
    "best_tf8_hyper = best_tf8_hyper.sort_values(by= 'mean (100th)',ascending= False)\n",
    "best_tf8_hyper.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "best_tf10_hyper = pd.read_csv('./tuning_results/tune_23/result/tuning_result_tfbind10_lengthscale6.5_sampling_lr0.05_delta0.25.csv')\n",
    "best_tf10_hyper = best_tf10_hyper[best_tf10_hyper['mean (100th)']>0.65]\n",
    "# best_tf8_hyper = None\n",
    "# for num_fit_samples in  [10000,12000,13000,14000,15000,16000,17000,18000] : \n",
    "#     best_tf8_hyper1 = pd.read_csv(f'./tuning_results/tune_23/result/tuning_result_tfbind8_num_fit_samples{num_fit_samples}_lengthscale5.75_sampling_lr0.05_delta0.25.csv')\n",
    "#     best_tf8_hyper1 = best_tf8_hyper1[best_tf8_hyper1['mean (100th)']>0.97] \n",
    "#     best_tf8_hyper = pd.concat([best_tf8_hyper1,best_tf8_hyper],ignore_index=True) \n",
    "# best_tf8_hyper = best_tf8_hyper.merge(best_tf10_hyper, on= ['sampling_lr','lengthscale','delta','eta','alpha','classifier_free_guidance_weight'])\n",
    "# best_tf8_hyper\n",
    "best_tf10_hyper\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "best_tf10_hyper = pd.read_csv('./tuning_results/tune_22_100steps/result/tuning_result_tfbind10_num_fit_samples10000_lengthscale6.0_sampling_lr0.05_delta0.25.csv')\n",
    "best_tf10_hyper = best_tf10_hyper[best_tf10_hyper['mean (100th)']>0.67]\n",
    "best_tf8_hyper  = pd.read_csv('./tuning_results/tune_20/result/tuning_result_tfbind8_lengthscale6.0_sampling_lr0.05_delta0.25.csv')\n",
    "best_tf8_hyper.merge(best_tf10_hyper, on = ['sampling_lr','eta','alpha','delta','lengthscale','classifier_free_guidance_weight'])\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import random\n",
    "import numpy as np \n",
    "\n",
    "def set_random_seed(SEED=1234):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "set_random_seed(0) \n",
    "set_random_seed(0)\n",
    "print(torch.randint(1,10,(10,))) \n",
    "print(1)\n",
    "set_random_seed(1) \n",
    "print(torch.randint(1,10,(10,)))\n",
    "set_random_seed(0) \n",
    "print(torch.randint(1,10,(10,)))\n",
    "set_random_seed(1) \n",
    "print(torch.randint(1,10,(10,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create offline_y with duplicate values, and some values repeating in a specific order\n",
    "offline_y = torch.tensor([1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 5.0, 4.0, 5.0, 4.0])\n",
    "offline_x = torch.arange(len(offline_y))  # For simplicity, x is just indices [0, 1, 2, ...]\n",
    "\n",
    "# First code:\n",
    "sorted_indices = torch.argsort(offline_y)[-5:]  # Top 5 largest elements\n",
    "offline_x_1 = offline_x[sorted_indices]\n",
    "offline_y_1 = offline_y[sorted_indices]\n",
    "\n",
    "# Re-sorting the top 5 largest elements\n",
    "indices_1 = torch.argsort(offline_y_1)\n",
    "offline_x_1 = offline_x_1[indices_1]\n",
    "offline_y_1 = offline_y_1[indices_1]\n",
    "\n",
    "print(f\"First Code - offline_x_1: {offline_x_1}, offline_y_1: {offline_y_1}\")\n",
    "\n",
    "# Second code:\n",
    "indices_2 = torch.argsort(offline_y)\n",
    "offline_x_2 = offline_x[indices_2]\n",
    "offline_y_2 = offline_y[indices_2]\n",
    "\n",
    "# Selecting the top 5 largest elements\n",
    "offline_x_2 = offline_x_2[-5:]\n",
    "offline_y_2 = offline_y_2[-5:]\n",
    "\n",
    "print(f\"Second Code - offline_x_2: {offline_x_2}, offline_y_2: {offline_y_2}\")\n",
    "\n",
    "# Check if outputs are identical\n",
    "print(torch.equal(offline_x_1, offline_x_2))  # Check if offline_x are the same\n",
    "print(torch.equal(offline_y_1, offline_y_2))  # Check if offline_y are the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_fit_samples</th>\n",
       "      <th>eta_tf</th>\n",
       "      <th>eta_cont</th>\n",
       "      <th>alpha</th>\n",
       "      <th>classifier_free_guidance_weight</th>\n",
       "      <th>mean (100th)_ant</th>\n",
       "      <th>std (100th)_ant</th>\n",
       "      <th>mean (100th)_dkitty</th>\n",
       "      <th>std (100th)_dkitty</th>\n",
       "      <th>mean (100th)_tf8</th>\n",
       "      <th>std (100th)_tf8</th>\n",
       "      <th>mean (100th)_tf10</th>\n",
       "      <th>std (100th)_tf10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.960583</td>\n",
       "      <td>0.014716</td>\n",
       "      <td>0.973676</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.98589</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.685157</td>\n",
       "      <td>0.052762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.964852</td>\n",
       "      <td>0.015509</td>\n",
       "      <td>0.973425</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>0.98589</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.685157</td>\n",
       "      <td>0.052762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.013557</td>\n",
       "      <td>0.972051</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.98589</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.685157</td>\n",
       "      <td>0.052762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_fit_samples  eta_tf  eta_cont  alpha  classifier_free_guidance_weight  \\\n",
       "0            15000     0.2      0.00    0.8                             -1.5   \n",
       "1            15000     0.2      0.05    0.8                             -1.5   \n",
       "2            15000     0.2      0.20    0.8                             -1.5   \n",
       "\n",
       "   mean (100th)_ant  std (100th)_ant  mean (100th)_dkitty  std (100th)_dkitty  \\\n",
       "0          0.960583         0.014716             0.973676            0.004914   \n",
       "1          0.964852         0.015509             0.973425            0.005035   \n",
       "2          0.965333         0.013557             0.972051            0.005118   \n",
       "\n",
       "   mean (100th)_tf8  std (100th)_tf8  mean (100th)_tf10  std (100th)_tf10  \n",
       "0           0.98589         0.006732           0.685157          0.052762  \n",
       "1           0.98589         0.006732           0.685157          0.052762  \n",
       "2           0.98589         0.006732           0.685157          0.052762  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "lengthscale = 6.25\n",
    "best_tf10_hyper = pd.read_csv(f'./tuning_results/tune_23/result/tuning_result_tfbind10_lengthscale{lengthscale}_sampling_lr0.05_delta0.25_1.csv')\n",
    "best_tf10_hyper = best_tf10_hyper[best_tf10_hyper['mean (100th)']>0.67]\n",
    "num_fit_samples_list = [10000,12000,13000,14000,15000,16000,17000,18000] \n",
    "best_tf8_hyper = None \n",
    "print(len(best_tf10_hyper))\n",
    "for num_fit_samples in num_fit_samples_list:\n",
    "    best_tf8_hyper_1 = pd.read_csv(f'./tuning_results/tune_23/result/tuning_result_tfbind8_num_fit_samples{num_fit_samples}_lengthscale{lengthscale}_sampling_lr0.05_delta0.25.csv')\n",
    "    best_tf8_hyper_1 = best_tf8_hyper_1[best_tf8_hyper_1['mean (100th)']>0.985] \n",
    "    best_tf8_hyper = pd.concat([best_tf8_hyper_1, best_tf8_hyper])  \n",
    "print(len(best_tf8_hyper))\n",
    "best_tf8_hyper= best_tf8_hyper.merge(best_tf10_hyper, on = ['sampling_lr','eta','alpha','delta','lengthscale','classifier_free_guidance_weight'])\n",
    "best_tf8_hyper = best_tf8_hyper[['num_fit_samples_x','eta','alpha','classifier_free_guidance_weight','mean (100th)_x','mean (100th)_y','std (100th)_x','std (100th)_y','mean (50th)_x','mean (50th)_y','std (50th)_x','std (50th)_y','mean (80th)_x','mean (80th)_y','std (80th)_x','std (80th)_y']]\n",
    "# Rename columns\n",
    "best_tf8_hyper = best_tf8_hyper.rename(columns={\n",
    "    'num_fit_samples_x': 'num_fit_samples',\n",
    "    'eta': 'eta_tf',\n",
    "    'alpha': 'alpha',\n",
    "    'classifier_free_guidance_weight': 'classifier_free_guidance_weight',\n",
    "    'mean (100th)_x': 'mean (100th)_tf8',\n",
    "    'mean (100th)_y': 'mean (100th)_tf10',\n",
    "    'std (100th)_x': 'std (100th)_tf8',\n",
    "    'std (100th)_y': 'std (100th)_tf10',\n",
    "    'mean (50th)_x': 'mean (50th)_tf8',\n",
    "    'mean (50th)_y': 'mean (50th)_tf10',\n",
    "    'std (50th)_x': 'std (50th)_tf8',\n",
    "    'std (50th)_y': 'std (50th)_tf10',\n",
    "    'mean (80th)_x': 'mean (80th)_tf8',\n",
    "    'mean (80th)_y': 'mean (80th)_tf10',\n",
    "    'std (80th)_x': 'std (80th)_tf8',\n",
    "    'std (80th)_y': 'std (80th)_tf10'\n",
    "\n",
    "})\n",
    "\n",
    "best_ant_hyper = pd.read_csv('tuning_results/tune_23/result/tuning_result_ant_lengthscale1.0_sampling_lr0.001_delta0.25.csv')\n",
    "best_ant_hyper = best_ant_hyper[best_ant_hyper['mean (100th)']>0.96] \n",
    "best_dkitty_hyper = pd.read_csv('tuning_results/tune_23/result/tuning_result_dkitty_lengthscale1.0_sampling_lr0.001_delta0.25.csv')\n",
    "best_dkitty_hyper = best_dkitty_hyper[best_dkitty_hyper['mean (100th)']>0.97]\n",
    "best_ant_hyper = best_ant_hyper.merge(best_dkitty_hyper,on = ['sampling_lr','eta','alpha','delta','lengthscale','classifier_free_guidance_weight']) \n",
    "\n",
    "best_ant_hyper = best_ant_hyper[['eta','alpha','classifier_free_guidance_weight','mean (100th)_x','mean (100th)_y','std (100th)_x','std (100th)_y','mean (50th)_x','mean (50th)_y','std (50th)_x','std (50th)_y','mean (80th)_x','mean (80th)_y','std (80th)_x','std (80th)_y']]\n",
    "\n",
    "best_ant_hyper = best_ant_hyper.rename(columns={\n",
    "    'eta': 'eta_cont',\n",
    "    'alpha': 'alpha',\n",
    "    'classifier_free_guidance_weight': 'classifier_free_guidance_weight',\n",
    "    'mean (100th)_x': 'mean (100th)_ant',\n",
    "    'mean (100th)_y': 'mean (100th)_dkitty',\n",
    "    'std (100th)_x': 'std (100th)_ant',\n",
    "    'std (100th)_y': 'std (100th)_dkitty',\n",
    "    'mean (50th)_x': 'mean (50th)_ant',\n",
    "    'mean (50th)_y': 'mean (50th)_dkitty',\n",
    "    'std (50th)_x': 'std (50th)_ant',\n",
    "    'std (50th)_y': 'std (50th)_dkitty',\n",
    "    'mean (80th)_x': 'mean (80th)_ant',\n",
    "    'mean (80th)_y': 'mean (80th)_dkitty',\n",
    "    'std (80th)_x': 'std (80th)_ant',\n",
    "    'std (80th)_y': 'std (80th)_dkitty'\n",
    "})\n",
    "best_ant_hyper = best_ant_hyper.merge(best_tf8_hyper, on=['alpha','classifier_free_guidance_weight'])\n",
    "best_ant_hyper[['num_fit_samples','eta_tf','eta_cont','alpha','classifier_free_guidance_weight','mean (100th)_ant','std (100th)_ant','mean (100th)_dkitty','std (100th)_dkitty','mean (100th)_tf8','std (100th)_tf8', 'mean (100th)_tf10', 'std (100th)_tf10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_fit_samples</th>\n",
       "      <th>eta_tf</th>\n",
       "      <th>eta_cont</th>\n",
       "      <th>alpha</th>\n",
       "      <th>classifier_free_guidance_weight</th>\n",
       "      <th>mean (50th)_ant</th>\n",
       "      <th>std (50th)_ant</th>\n",
       "      <th>mean (50th)_dkitty</th>\n",
       "      <th>std (50th)_dkitty</th>\n",
       "      <th>mean (50th)_tf8</th>\n",
       "      <th>std (50th)_tf8</th>\n",
       "      <th>mean (50th)_tf10</th>\n",
       "      <th>std (50th)_tf10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.716448</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.921065</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.674995</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.472681</td>\n",
       "      <td>0.004093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.720881</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>0.920798</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.674995</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.472681</td>\n",
       "      <td>0.004093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.711568</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>0.919340</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.674995</td>\n",
       "      <td>0.026171</td>\n",
       "      <td>0.472681</td>\n",
       "      <td>0.004093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_fit_samples  eta_tf  eta_cont  alpha  classifier_free_guidance_weight  \\\n",
       "0            15000     0.2      0.00    0.8                             -1.5   \n",
       "1            15000     0.2      0.05    0.8                             -1.5   \n",
       "2            15000     0.2      0.20    0.8                             -1.5   \n",
       "\n",
       "   mean (50th)_ant  std (50th)_ant  mean (50th)_dkitty  std (50th)_dkitty  \\\n",
       "0         0.716448        0.020384            0.921065           0.002660   \n",
       "1         0.720881        0.013926            0.920798           0.002807   \n",
       "2         0.711568        0.013848            0.919340           0.002913   \n",
       "\n",
       "   mean (50th)_tf8  std (50th)_tf8  mean (50th)_tf10  std (50th)_tf10  \n",
       "0         0.674995        0.026171          0.472681         0.004093  \n",
       "1         0.674995        0.026171          0.472681         0.004093  \n",
       "2         0.674995        0.026171          0.472681         0.004093  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ant_hyper[['num_fit_samples','eta_tf','eta_cont','alpha','classifier_free_guidance_weight','mean (50th)_ant','std (50th)_ant','mean (50th)_dkitty','std (50th)_dkitty','mean (50th)_tf8','std (50th)_tf8', 'mean (50th)_tf10', 'std (50th)_tf10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from .npy file\n",
    "data = [] \n",
    "data.append(np.load(\"L2HD_full_result_distribution\\AntMorphology-Exact-v0_full_distribution_final_results_0.npy\").flatten())\n",
    "data.append(np.load(\"L2HD_full_result_distribution\\AntMorphology-Exact-v0_full_distribution_final_results_1.npy\").flatten())\n",
    "# # Plot boxplot\n",
    "plt.boxplot(data)\n",
    "# plt.xlabel([\"L2HD\",\"L2HD-2\"]) # Adjust label as needed\n",
    "# plt.ylabel(\"Performance\")\n",
    "# plt.title(\"Boxplot of Performance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "res = [1,2,3] \n",
    "res = np.array(res) \n",
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the directory and baselines\n",
    "# task_name = 'AntMorphology-Exact-v0'\n",
    "# task_name = 'DkittyMorphology-Exact-v0'\n",
    "# task_name = 'TFBind8-Exact-v0'\n",
    "task_name = 'TFBind10-Exact-v0'\n",
    "\n",
    "base_dir = f'full_result_distribution/{task_name}'\n",
    "baselines = ['cma-es', 'coms', 'gradient-ascent', 'mins', 'tri-mentoring', 'ict', 'L2HD']\n",
    "highlight_baseline = 'L2HD'\n",
    "short_labels = ['Cma-es', 'COMS', 'GA', 'MINS', 'Tri*', 'ICT', 'L2HD']\n",
    "task_to_name = {'AntMorphology-Exact-v0': 'Ant', 'DkittyMorphology-Exact-v0': 'Dkitty', 'TFBind8-Exact-v0': \"TFBind8\", 'TFBind10-Exact-v0': \"TFBind10\"}\n",
    "\n",
    "# Initialize a dictionary to store the averaged results for each baseline\n",
    "averaged_results = {}\n",
    "\n",
    "# Iterate over each baseline\n",
    "for baseline in baselines:\n",
    "    seed_data = []\n",
    "    \n",
    "    # Collect and sort data for each seed\n",
    "    for seed in range(8):\n",
    "        file_path = f'{base_dir}/{baseline}/seed{seed}.npy'\n",
    "        if os.path.exists(file_path):\n",
    "            data = np.load(file_path).flatten()\n",
    "            sorted_data = np.sort(data)\n",
    "            seed_data.append(sorted_data)\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "\n",
    "    # Compute element-wise average across seeds\n",
    "    if seed_data:\n",
    "        seed_data = np.array(seed_data)\n",
    "        averaged_results[baseline] = seed_data.flatten()\n",
    "\n",
    "# Prepare data for the violin plot\n",
    "plot_data = [averaged_results[baseline] for baseline in baselines]\n",
    "l2hd_data = averaged_results[highlight_baseline]\n",
    "l2hd_max = np.max(l2hd_data)\n",
    "l2hd_median = np.median(l2hd_data)\n",
    "\n",
    "# Create violin plot\n",
    "plt.figure(figsize=(5, 4))\n",
    "violin_parts = plt.violinplot(plot_data, showmedians=True)\n",
    "\n",
    "# Set color and opacity for all violins, and highlight \"L2HD\" in green\n",
    "for i, body in enumerate(violin_parts['bodies']):\n",
    "    if i == baselines.index(highlight_baseline):\n",
    "        body.set_facecolor('purple')  # Set green color for \"L2HD\"\n",
    "        body.set_alpha(0.6)  # Higher opacity for emphasis\n",
    "    else:\n",
    "        body.set_alpha(0.4)  # Lower opacity for other baselines\n",
    "\n",
    "# Add dashed lines for max and median values of \"L2HD\"\n",
    "plt.axhline(y=l2hd_max, color='green', linestyle='--', linewidth=1.5, alpha=1.0, label=f'{highlight_baseline} max')\n",
    "plt.axhline(y=l2hd_median, color='red', linestyle='--', linewidth=1.5, alpha=1.0, label=f'{highlight_baseline} median')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xticks(ticks=range(1, len(baselines) + 1), labels=short_labels, rotation=60)\n",
    "plt.xlabel(task_to_name[task_name])\n",
    "plt.ylabel(\"Values\")\n",
    "\n",
    "# Title with newline for spacing\n",
    "plt.title(\"Score of found designs\\n\")\n",
    "\n",
    "# Move legend below the title but above the plot\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15), frameon=False, \n",
    "           facecolor='white', framealpha=0.5, edgecolor='none', ncol=7)\n",
    "\n",
    "# Adjust layout to ensure the plot fits with the title and legend properly\n",
    "plt.tight_layout(pad=3.0)  # Increase padding to make room for the legend\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define the path to the input file\n",
    "input_file = 'tf8-tri.txt'  # Adjust this to the correct path\n",
    "\n",
    "# Directory where the results will be saved\n",
    "output_dir = 'full_result_distribution/TFBind8-Exact-v0/tri-mentoring/'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize a dictionary to store the scores for each seed\n",
    "seed_scores = {}\n",
    "\n",
    "# Read the input file\n",
    "with open(input_file, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Regex pattern to extract seed and score data\n",
    "seed_pattern = re.compile(r\"Current seed is (\\d+)\")\n",
    "score_pattern = re.compile(r\"candidate (\\d+) score before .+ score now ([-\\d.]+)\")\n",
    "\n",
    "# Parse the file\n",
    "current_seed = None\n",
    "scores = []\n",
    "\n",
    "for line in lines:\n",
    "    # Check for seed change\n",
    "    seed_match = seed_pattern.search(line)\n",
    "    if seed_match:\n",
    "        # If there's an existing seed, save the collected scores\n",
    "        if current_seed is not None:\n",
    "            # Save the scores for the current seed\n",
    "            seed_scores[current_seed] = np.array(scores)\n",
    "        \n",
    "        # Start collecting scores for the new seed\n",
    "        current_seed = int(seed_match.group(1))\n",
    "        scores = []  # Reset the scores list for the new seed\n",
    "\n",
    "    # Check for score lines\n",
    "    score_match = score_pattern.search(line)\n",
    "    if score_match:\n",
    "        # Append the score to the list\n",
    "        score = float(score_match.group(2))\n",
    "        scores.append(score)\n",
    "\n",
    "# After the loop, save the last seed's data\n",
    "if current_seed is not None:\n",
    "    seed_scores[current_seed] = np.array(scores)\n",
    "\n",
    "# Now, save each seed's scores to an .npy file\n",
    "for seed, scores in seed_scores.items():\n",
    "    assert(scores.shape[0]==128)\n",
    "    output_file = os.path.join(output_dir, f'seed{seed}.npy')\n",
    "    np.save(output_file, scores)\n",
    "\n",
    "print(\"Scores have been saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.67415]\n",
      "[2.0045009]\n",
      "[3.0764363]\n",
      "[2.4650018]\n",
      "[0.4432688]\n",
      "[0.3487901]\n",
      "[1.6086879]\n",
      "[0.8817995]\n"
     ]
    }
   ],
   "source": [
    "# max_cmaes_scores = 0 \n",
    "for seed in range(8):\n",
    "    cmaes_scores = np.load(f'full_result_distribution/AntMorphology-Exact-v0/cma-es/seed{seed}.npy')\n",
    "    print(max(cmaes_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_fit_samples</th>\n",
       "      <th>eta_tf</th>\n",
       "      <th>eta_cont</th>\n",
       "      <th>alpha</th>\n",
       "      <th>classifier_free_guidance_weight</th>\n",
       "      <th>mean (80th)_ant</th>\n",
       "      <th>std (80th)_ant</th>\n",
       "      <th>mean (80th)_dkitty</th>\n",
       "      <th>std (80th)_dkitty</th>\n",
       "      <th>mean (80th)_tf8</th>\n",
       "      <th>std (80th)_tf8</th>\n",
       "      <th>mean (80th)_tf10</th>\n",
       "      <th>std (80th)_tf10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.839375</td>\n",
       "      <td>0.010242</td>\n",
       "      <td>0.940125</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.83926</td>\n",
       "      <td>0.014803</td>\n",
       "      <td>0.525875</td>\n",
       "      <td>0.00717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.841409</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.939602</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.83926</td>\n",
       "      <td>0.014803</td>\n",
       "      <td>0.525875</td>\n",
       "      <td>0.00717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.847239</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.938429</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.83926</td>\n",
       "      <td>0.014803</td>\n",
       "      <td>0.525875</td>\n",
       "      <td>0.00717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_fit_samples  eta_tf  eta_cont  alpha  classifier_free_guidance_weight  \\\n",
       "0            15000     0.2      0.00    0.8                             -1.5   \n",
       "1            15000     0.2      0.05    0.8                             -1.5   \n",
       "2            15000     0.2      0.20    0.8                             -1.5   \n",
       "\n",
       "   mean (80th)_ant  std (80th)_ant  mean (80th)_dkitty  std (80th)_dkitty  \\\n",
       "0         0.839375        0.010242            0.940125           0.001418   \n",
       "1         0.841409        0.010893            0.939602           0.001767   \n",
       "2         0.847239        0.005095            0.938429           0.001829   \n",
       "\n",
       "   mean (80th)_tf8  std (80th)_tf8  mean (80th)_tf10  std (80th)_tf10  \n",
       "0          0.83926        0.014803          0.525875          0.00717  \n",
       "1          0.83926        0.014803          0.525875          0.00717  \n",
       "2          0.83926        0.014803          0.525875          0.00717  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ant_hyper[['num_fit_samples','eta_tf','eta_cont','alpha','classifier_free_guidance_weight','mean (80th)_ant','std (80th)_ant','mean (80th)_dkitty','std (80th)_dkitty','mean (80th)_tf8','std (80th)_tf8', 'mean (80th)_tf10', 'std (80th)_tf10']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "best_ant_hyper = pd.read_csv('tuning_results/tune_23/result/tuning_result_ant_lengthscale1.0_sampling_lr0.001_delta0.25.csv')\n",
    "best_ant_hyper = best_ant_hyper[best_ant_hyper['mean (100th)']>0.96]\n",
    "#best_ant_hyper = best_ant_hyper[best_ant_hyper['alpha']==0.7]\n",
    "#best_ant_hyper = best_ant_hyper[best_ant_hyper['eta']==0.05]\n",
    "best_dkitty_hyper = pd.read_csv('tuning_results/tune_23/result/tuning_result_dkitty_lengthscale1.0_sampling_lr0.001_delta0.25.csv')\n",
    "best_dkitty_hyper = best_dkitty_hyper[best_dkitty_hyper['mean (100th)']>0.96]\n",
    "best_dkitty_hyper.merge(best_ant_hyper,on=['sampling_lr','lengthscale','delta','eta','alpha','classifier_free_guidance_weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n='abc'\n",
    "x = f'{n}12'\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
