{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "file_path = './tuning_results/tune_19/result/tuning_result_tfbind8_lr0.05.csv' \n",
    "df = pd.read_csv(file_path) \n",
    "df = df.sort_values(by='mean (100th)',ascending=False)\n",
    "df = df[df['mean (100th)']>0.95]\n",
    "print(len(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_fit_samples</th>\n",
       "      <th>sampling_lr</th>\n",
       "      <th>lengthscale</th>\n",
       "      <th>delta</th>\n",
       "      <th>eta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>classifier_free_guidance_weight</th>\n",
       "      <th>mean (100th)</th>\n",
       "      <th>std (100th)</th>\n",
       "      <th>mean (80th)</th>\n",
       "      <th>std (80th)</th>\n",
       "      <th>mean (50th)</th>\n",
       "      <th>std (50th)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.985150</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.774306</td>\n",
       "      <td>0.024396</td>\n",
       "      <td>0.606669</td>\n",
       "      <td>0.016217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.985150</td>\n",
       "      <td>0.007601</td>\n",
       "      <td>0.778777</td>\n",
       "      <td>0.022476</td>\n",
       "      <td>0.607109</td>\n",
       "      <td>0.016201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.984104</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>0.774083</td>\n",
       "      <td>0.023263</td>\n",
       "      <td>0.609005</td>\n",
       "      <td>0.020505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.983372</td>\n",
       "      <td>0.010869</td>\n",
       "      <td>0.810617</td>\n",
       "      <td>0.012651</td>\n",
       "      <td>0.613903</td>\n",
       "      <td>0.010103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.983372</td>\n",
       "      <td>0.010869</td>\n",
       "      <td>0.810700</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>0.613269</td>\n",
       "      <td>0.009582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.983261</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>0.772716</td>\n",
       "      <td>0.021107</td>\n",
       "      <td>0.607427</td>\n",
       "      <td>0.021010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.983261</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>0.774083</td>\n",
       "      <td>0.023263</td>\n",
       "      <td>0.609480</td>\n",
       "      <td>0.022091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>0.982898</td>\n",
       "      <td>0.010231</td>\n",
       "      <td>0.806030</td>\n",
       "      <td>0.014509</td>\n",
       "      <td>0.615642</td>\n",
       "      <td>0.014410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.982817</td>\n",
       "      <td>0.010594</td>\n",
       "      <td>0.807115</td>\n",
       "      <td>0.017348</td>\n",
       "      <td>0.608907</td>\n",
       "      <td>0.013978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.982717</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.797886</td>\n",
       "      <td>0.018735</td>\n",
       "      <td>0.616540</td>\n",
       "      <td>0.027376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.982717</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>0.793216</td>\n",
       "      <td>0.021562</td>\n",
       "      <td>0.612873</td>\n",
       "      <td>0.021216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.982653</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.786316</td>\n",
       "      <td>0.027504</td>\n",
       "      <td>0.605946</td>\n",
       "      <td>0.023327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.982247</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>0.787124</td>\n",
       "      <td>0.028426</td>\n",
       "      <td>0.618130</td>\n",
       "      <td>0.015504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>13000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.982247</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>0.788201</td>\n",
       "      <td>0.029154</td>\n",
       "      <td>0.617953</td>\n",
       "      <td>0.017115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.981817</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.798728</td>\n",
       "      <td>0.017881</td>\n",
       "      <td>0.609606</td>\n",
       "      <td>0.010299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.981726</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>0.798798</td>\n",
       "      <td>0.023007</td>\n",
       "      <td>0.610530</td>\n",
       "      <td>0.023437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.981726</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>0.792102</td>\n",
       "      <td>0.025404</td>\n",
       "      <td>0.611808</td>\n",
       "      <td>0.025824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.981493</td>\n",
       "      <td>0.011067</td>\n",
       "      <td>0.810325</td>\n",
       "      <td>0.024434</td>\n",
       "      <td>0.612194</td>\n",
       "      <td>0.015778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.981493</td>\n",
       "      <td>0.011067</td>\n",
       "      <td>0.810569</td>\n",
       "      <td>0.024135</td>\n",
       "      <td>0.613449</td>\n",
       "      <td>0.018207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.981493</td>\n",
       "      <td>0.011067</td>\n",
       "      <td>0.809293</td>\n",
       "      <td>0.024341</td>\n",
       "      <td>0.612641</td>\n",
       "      <td>0.017368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>0.981398</td>\n",
       "      <td>0.011068</td>\n",
       "      <td>0.794474</td>\n",
       "      <td>0.022343</td>\n",
       "      <td>0.604675</td>\n",
       "      <td>0.018229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.980682</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.789359</td>\n",
       "      <td>0.028242</td>\n",
       "      <td>0.617337</td>\n",
       "      <td>0.023851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.980568</td>\n",
       "      <td>0.008677</td>\n",
       "      <td>0.793424</td>\n",
       "      <td>0.020437</td>\n",
       "      <td>0.614883</td>\n",
       "      <td>0.024363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.980466</td>\n",
       "      <td>0.011599</td>\n",
       "      <td>0.793961</td>\n",
       "      <td>0.027511</td>\n",
       "      <td>0.605917</td>\n",
       "      <td>0.017143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.980466</td>\n",
       "      <td>0.011599</td>\n",
       "      <td>0.792231</td>\n",
       "      <td>0.025512</td>\n",
       "      <td>0.605986</td>\n",
       "      <td>0.020623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.980028</td>\n",
       "      <td>0.007742</td>\n",
       "      <td>0.793344</td>\n",
       "      <td>0.023359</td>\n",
       "      <td>0.611274</td>\n",
       "      <td>0.018766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_fit_samples  sampling_lr  lengthscale  delta   eta  alpha  \\\n",
       "175            13000         0.05          5.3   0.25  0.50   0.85   \n",
       "179            13000         0.05          5.3   0.25  0.50   0.80   \n",
       "171            13000         0.05          5.3   0.25  0.50   0.90   \n",
       "59             17000         0.05          5.3   0.25  0.10   0.80   \n",
       "55             17000         0.05          5.3   0.25  0.10   0.85   \n",
       "163            13000         0.05          5.3   0.25  0.50   1.00   \n",
       "167            13000         0.05          5.3   0.25  0.50   0.95   \n",
       "133            15000         0.05          5.3   0.25  0.30   0.85   \n",
       "39             17000         0.05          5.3   0.25  0.05   0.80   \n",
       "52             15000         0.05          5.3   0.25  0.10   0.85   \n",
       "68             15000         0.05          5.3   0.25  0.15   0.90   \n",
       "100            15000         0.05          5.3   0.25  0.25   1.00   \n",
       "147            13000         0.05          5.3   0.25  0.40   0.95   \n",
       "143            13000         0.05          5.3   0.25  0.40   1.00   \n",
       "116            15000         0.05          5.3   0.25  0.25   0.80   \n",
       "92             15000         0.05          5.3   0.25  0.20   0.85   \n",
       "88             15000         0.05          5.3   0.25  0.20   0.90   \n",
       "11             17000         0.05          5.3   0.25  0.00   0.90   \n",
       "15             17000         0.05          5.3   0.25  0.00   0.85   \n",
       "19             17000         0.05          5.3   0.25  0.00   0.80   \n",
       "121            15000         0.05          5.3   0.25  0.30   1.00   \n",
       "0              15000         0.05          5.3   0.25  0.00   1.00   \n",
       "72             15000         0.05          5.3   0.25  0.15   0.85   \n",
       "132            15000         0.05          5.3   0.25  0.30   0.85   \n",
       "136            15000         0.05          5.3   0.25  0.30   0.80   \n",
       "112            15000         0.05          5.3   0.25  0.25   0.85   \n",
       "\n",
       "     classifier_free_guidance_weight  mean (100th)  std (100th)  mean (80th)  \\\n",
       "175                             -1.5      0.985150     0.007601     0.774306   \n",
       "179                             -1.5      0.985150     0.007601     0.778777   \n",
       "171                             -1.5      0.984104     0.007306     0.774083   \n",
       "59                              -1.5      0.983372     0.010869     0.810617   \n",
       "55                              -1.5      0.983372     0.010869     0.810700   \n",
       "163                             -1.5      0.983261     0.005998     0.772716   \n",
       "167                             -1.5      0.983261     0.005998     0.774083   \n",
       "133                             -2.5      0.982898     0.010231     0.806030   \n",
       "39                              -1.5      0.982817     0.010594     0.807115   \n",
       "52                              -3.0      0.982717     0.008773     0.797886   \n",
       "68                              -3.0      0.982717     0.008773     0.793216   \n",
       "100                             -3.0      0.982653     0.008772     0.786316   \n",
       "147                             -1.5      0.982247     0.009126     0.787124   \n",
       "143                             -1.5      0.982247     0.009126     0.788201   \n",
       "116                             -3.0      0.981817     0.009653     0.798728   \n",
       "92                              -3.0      0.981726     0.008256     0.798798   \n",
       "88                              -3.0      0.981726     0.008256     0.792102   \n",
       "11                              -1.5      0.981493     0.011067     0.810325   \n",
       "15                              -1.5      0.981493     0.011067     0.810569   \n",
       "19                              -1.5      0.981493     0.011067     0.809293   \n",
       "121                             -2.5      0.981398     0.011068     0.794474   \n",
       "0                               -3.0      0.980682     0.013788     0.789359   \n",
       "72                              -3.0      0.980568     0.008677     0.793424   \n",
       "132                             -3.0      0.980466     0.011599     0.793961   \n",
       "136                             -3.0      0.980466     0.011599     0.792231   \n",
       "112                             -3.0      0.980028     0.007742     0.793344   \n",
       "\n",
       "     std (80th)  mean (50th)  std (50th)  \n",
       "175    0.024396     0.606669    0.016217  \n",
       "179    0.022476     0.607109    0.016201  \n",
       "171    0.023263     0.609005    0.020505  \n",
       "59     0.012651     0.613903    0.010103  \n",
       "55     0.013062     0.613269    0.009582  \n",
       "163    0.021107     0.607427    0.021010  \n",
       "167    0.023263     0.609480    0.022091  \n",
       "133    0.014509     0.615642    0.014410  \n",
       "39     0.017348     0.608907    0.013978  \n",
       "52     0.018735     0.616540    0.027376  \n",
       "68     0.021562     0.612873    0.021216  \n",
       "100    0.027504     0.605946    0.023327  \n",
       "147    0.028426     0.618130    0.015504  \n",
       "143    0.029154     0.617953    0.017115  \n",
       "116    0.017881     0.609606    0.010299  \n",
       "92     0.023007     0.610530    0.023437  \n",
       "88     0.025404     0.611808    0.025824  \n",
       "11     0.024434     0.612194    0.015778  \n",
       "15     0.024135     0.613449    0.018207  \n",
       "19     0.024341     0.612641    0.017368  \n",
       "121    0.022343     0.604675    0.018229  \n",
       "0      0.028242     0.617337    0.023851  \n",
       "72     0.020437     0.614883    0.024363  \n",
       "132    0.027511     0.605917    0.017143  \n",
       "136    0.025512     0.605986    0.020623  \n",
       "112    0.023359     0.611274    0.018766  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "num_fit_samples_list = [10000,12000,13000,14000,15000,16000,17000,18000] \n",
    "best_tf8_hyper = None \n",
    "lengthscale = 5.3\n",
    "for num_fit_samples in num_fit_samples_list: \n",
    "    best_tf8_hyper1 =  pd.read_csv(f'tuning_results/tune_23/result/tuning_result_tfbind8_num_fit_samples{num_fit_samples}_lengthscale{lengthscale}_sampling_lr0.05_delta0.25.csv')\n",
    "    best_tf8_hyper1 = best_tf8_hyper1[best_tf8_hyper1['mean (100th)']>0.980]\n",
    "    best_tf8_hyper = pd.concat([best_tf8_hyper,best_tf8_hyper1])\n",
    "best_tf8_hyper_1 = best_tf8_hyper[['eta', 'alpha', 'classifier_free_guidance_weight']].to_numpy()\n",
    "best_tf8_hyper_1 = np.unique(best_tf8_hyper_1,axis=0)\n",
    "print(len(best_tf8_hyper_1))\n",
    "best_tf8_hyper = best_tf8_hyper.sort_values(by= 'mean (100th)',ascending= False)\n",
    "best_tf8_hyper.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "best_tf10_hyper = pd.read_csv('./tuning_results/tune_23/result/tuning_result_tfbind10_lengthscale6.5_sampling_lr0.05_delta0.25.csv')\n",
    "best_tf10_hyper = best_tf10_hyper[best_tf10_hyper['mean (100th)']>0.65]\n",
    "# best_tf8_hyper = None\n",
    "# for num_fit_samples in  [10000,12000,13000,14000,15000,16000,17000,18000] : \n",
    "#     best_tf8_hyper1 = pd.read_csv(f'./tuning_results/tune_23/result/tuning_result_tfbind8_num_fit_samples{num_fit_samples}_lengthscale5.75_sampling_lr0.05_delta0.25.csv')\n",
    "#     best_tf8_hyper1 = best_tf8_hyper1[best_tf8_hyper1['mean (100th)']>0.97] \n",
    "#     best_tf8_hyper = pd.concat([best_tf8_hyper1,best_tf8_hyper],ignore_index=True) \n",
    "# best_tf8_hyper = best_tf8_hyper.merge(best_tf10_hyper, on= ['sampling_lr','lengthscale','delta','eta','alpha','classifier_free_guidance_weight'])\n",
    "# best_tf8_hyper\n",
    "best_tf10_hyper\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "best_tf10_hyper = pd.read_csv('./tuning_results/tune_22_100steps/result/tuning_result_tfbind10_num_fit_samples10000_lengthscale6.0_sampling_lr0.05_delta0.25.csv')\n",
    "best_tf10_hyper = best_tf10_hyper[best_tf10_hyper['mean (100th)']>0.67]\n",
    "best_tf8_hyper  = pd.read_csv('./tuning_results/tune_20/result/tuning_result_tfbind8_lengthscale6.0_sampling_lr0.05_delta0.25.csv')\n",
    "best_tf8_hyper.merge(best_tf10_hyper, on = ['sampling_lr','eta','alpha','delta','lengthscale','classifier_free_guidance_weight'])\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import random\n",
    "import numpy as np \n",
    "\n",
    "def set_random_seed(SEED=1234):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "set_random_seed(0) \n",
    "set_random_seed(0)\n",
    "print(torch.randint(1,10,(10,))) \n",
    "print(1)\n",
    "set_random_seed(1) \n",
    "print(torch.randint(1,10,(10,)))\n",
    "set_random_seed(0) \n",
    "print(torch.randint(1,10,(10,)))\n",
    "set_random_seed(1) \n",
    "print(torch.randint(1,10,(10,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create offline_y with duplicate values, and some values repeating in a specific order\n",
    "offline_y = torch.tensor([1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 5.0, 4.0, 5.0, 4.0])\n",
    "offline_x = torch.arange(len(offline_y))  # For simplicity, x is just indices [0, 1, 2, ...]\n",
    "\n",
    "# First code:\n",
    "sorted_indices = torch.argsort(offline_y)[-5:]  # Top 5 largest elements\n",
    "offline_x_1 = offline_x[sorted_indices]\n",
    "offline_y_1 = offline_y[sorted_indices]\n",
    "\n",
    "# Re-sorting the top 5 largest elements\n",
    "indices_1 = torch.argsort(offline_y_1)\n",
    "offline_x_1 = offline_x_1[indices_1]\n",
    "offline_y_1 = offline_y_1[indices_1]\n",
    "\n",
    "print(f\"First Code - offline_x_1: {offline_x_1}, offline_y_1: {offline_y_1}\")\n",
    "\n",
    "# Second code:\n",
    "indices_2 = torch.argsort(offline_y)\n",
    "offline_x_2 = offline_x[indices_2]\n",
    "offline_y_2 = offline_y[indices_2]\n",
    "\n",
    "# Selecting the top 5 largest elements\n",
    "offline_x_2 = offline_x_2[-5:]\n",
    "offline_y_2 = offline_y_2[-5:]\n",
    "\n",
    "print(f\"Second Code - offline_x_2: {offline_x_2}, offline_y_2: {offline_y_2}\")\n",
    "\n",
    "# Check if outputs are identical\n",
    "print(torch.equal(offline_x_1, offline_x_2))  # Check if offline_x are the same\n",
    "print(torch.equal(offline_y_1, offline_y_2))  # Check if offline_y are the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "490\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_fit_samples_x</th>\n",
       "      <th>eta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>classifier_free_guidance_weight</th>\n",
       "      <th>mean (100th)_x</th>\n",
       "      <th>mean (100th)_y</th>\n",
       "      <th>std (100th)_x</th>\n",
       "      <th>std (100th)_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.988339</td>\n",
       "      <td>0.66953</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.047593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.988339</td>\n",
       "      <td>0.66953</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.047593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.988339</td>\n",
       "      <td>0.66953</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.047593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.981212</td>\n",
       "      <td>0.66953</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.047593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.981212</td>\n",
       "      <td>0.66953</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.047593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.981212</td>\n",
       "      <td>0.66953</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.047593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.981411</td>\n",
       "      <td>0.66953</td>\n",
       "      <td>0.008135</td>\n",
       "      <td>0.047593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.981411</td>\n",
       "      <td>0.66953</td>\n",
       "      <td>0.008135</td>\n",
       "      <td>0.047593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_fit_samples_x   eta  alpha  classifier_free_guidance_weight  \\\n",
       "0              17000  0.75   0.90                             -1.5   \n",
       "1              17000  0.75   0.85                             -1.5   \n",
       "2              17000  0.75   0.80                             -1.5   \n",
       "3              16000  0.75   0.90                             -1.5   \n",
       "4              16000  0.75   0.85                             -1.5   \n",
       "5              16000  0.75   0.80                             -1.5   \n",
       "6              15000  0.75   0.85                             -1.5   \n",
       "7              15000  0.75   0.80                             -1.5   \n",
       "\n",
       "   mean (100th)_x  mean (100th)_y  std (100th)_x  std (100th)_y  \n",
       "0        0.988339         0.66953       0.007687       0.047593  \n",
       "1        0.988339         0.66953       0.007687       0.047593  \n",
       "2        0.988339         0.66953       0.007687       0.047593  \n",
       "3        0.981212         0.66953       0.009888       0.047593  \n",
       "4        0.981212         0.66953       0.009888       0.047593  \n",
       "5        0.981212         0.66953       0.009888       0.047593  \n",
       "6        0.981411         0.66953       0.008135       0.047593  \n",
       "7        0.981411         0.66953       0.008135       0.047593  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "lengthscale = 6.25\n",
    "best_tf10_hyper = pd.read_csv(f'./tuning_results/tune_23/result/tuning_result_tfbind10_lengthscale{lengthscale}_sampling_lr0.05_delta0.25.csv')\n",
    "best_tf10_hyper = best_tf10_hyper[best_tf10_hyper['mean (100th)']>0.6695]\n",
    "num_fit_samples_list = [10000,12000,13000,14000,15000,16000,17000,18000] \n",
    "best_tf8_hyper = None \n",
    "print(len(best_tf10_hyper))\n",
    "for num_fit_samples in num_fit_samples_list:\n",
    "    best_tf8_hyper_1 = pd.read_csv(f'./tuning_results/tune_23/result/tuning_result_tfbind8_num_fit_samples{num_fit_samples}_lengthscale{lengthscale}_sampling_lr0.05_delta0.25.csv')\n",
    "    best_tf8_hyper_1 = best_tf8_hyper_1[best_tf8_hyper_1['mean (100th)']>0.9795] \n",
    "    best_tf8_hyper = pd.concat([best_tf8_hyper_1, best_tf8_hyper])  \n",
    "print(len(best_tf8_hyper))\n",
    "best_tf8_hyper= best_tf8_hyper.merge(best_tf10_hyper, on = ['sampling_lr','eta','alpha','delta','lengthscale','classifier_free_guidance_weight'])\n",
    "best_tf8_hyper[['num_fit_samples_x','eta','alpha','classifier_free_guidance_weight','mean (100th)_x','mean (100th)_y','std (100th)_x','std (100th)_y']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "best_ant_hyper = pd.read_csv('tuning_results/tune_23/result/tuning_result_ant_lengthscale1.0_sampling_lr0.001_delta0.25.csv')\n",
    "best_ant_hyper = best_ant_hyper[best_ant_hyper['mean (100th)']>0.96]\n",
    "#best_ant_hyper = best_ant_hyper[best_ant_hyper['alpha']==0.7]\n",
    "#best_ant_hyper = best_ant_hyper[best_ant_hyper['eta']==0.05]\n",
    "best_dkitty_hyper = pd.read_csv('tuning_results/tune_23/result/tuning_result_dkitty_lengthscale1.0_sampling_lr0.001_delta0.25.csv')\n",
    "best_dkitty_hyper = best_dkitty_hyper[best_dkitty_hyper['mean (100th)']>0.96]\n",
    "best_dkitty_hyper.merge(best_ant_hyper,on=['sampling_lr','lengthscale','delta','eta','alpha','classifier_free_guidance_weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n='abc'\n",
    "x = f'{n}12'\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
